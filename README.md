<div>
# Build Gradio inference app

## Step1:
Train Model on Colab for 10 epochs and download scripted model model.script.pt and create a tar.gz file named model.script.pt.tar.gz

## Step2:
Build docker image using command below (inference code is in src/demo.py):

docker build -t timm-gradio-cifar10

## Step3:
Start gradio app by running docker image at port 8080

docker run -p 8080:7860 timm-gradio-cifar10

## Step4:
Push the docker image to dockerhub

docker login
docker image tag timm-gradio-cifar10 monimoyp/timm-gradio-cifar10:latest
ocker image push monimoyp/timm-gradio-cifar10:latest




# Train on Docker and Predict on cog using Pytorch ligtning and Hydra Template

This repository is created using template from https://github.com/ashleve/lightning-hydra-template.<br>

Building of Docker images and downloading of cog binary is by building Makefile. CIFAR10 images are trained on Docker using Pytorch lighning, timm and hydra template.
  
Prediction on any image is done using cog by integrating timm.

</div>

<br>

## ðŸ“ŒÂ How to Use

**How to build:**

make build

**How to train:** 

docker run -v \`pwd\`:/workspace/project cifar10_emlo python3 src/train.py experiment=cifar

**How to predict using cog:**

make predict image=\<Image File\>

Example:
make predict image=input.jpg

**How to tune parameters of cifar10 using resnet**

python3 src/train.py -m experiment=cifar hparams_search=cifar10_optuna

<br>



## Project Structure

The directory structure of new project looks like this:

```
â”œâ”€â”€ configs                   <- Hydra configuration files
â”‚   â”œâ”€â”€ callbacks                <- Callbacks configs
â”‚   â”œâ”€â”€ datamodule               <- Datamodule configs
â”‚   â”œâ”€â”€ debug                    <- Debugging configs
â”‚   â”œâ”€â”€ experiment               <- Experiment configs
â”‚   â”œâ”€â”€ extras                   <- Extra utilities configs
â”‚   â”œâ”€â”€ hparams_search           <- Hyperparameter search configs
â”‚   â”œâ”€â”€ hydra                    <- Hydra configs
â”‚   â”œâ”€â”€ local                    <- Local configs
â”‚   â”œâ”€â”€ logger                   <- Logger configs
â”‚   â”œâ”€â”€ model                    <- Model configs
â”‚   â”œâ”€â”€ paths                    <- Project paths configs
â”‚   â”œâ”€â”€ trainer                  <- Trainer configs
â”‚   â”‚
â”‚   â”œâ”€â”€ eval.yaml             <- Main config for evaluation
â”‚   â””â”€â”€ train.yaml            <- Main config for training
â”‚
â”œâ”€â”€ data                   <- Project data
â”‚
â”œâ”€â”€ logs                   <- Logs generated by hydra and lightning loggers
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                             the creator's initials, and a short `-` delimited description,
â”‚                             e.g. `1.0-jqp-initial-data-exploration.ipynb`.
â”‚
â”œâ”€â”€ scripts                <- Shell scripts
â”‚
â”œâ”€â”€ src                    <- Source code
â”‚   â”œâ”€â”€ datamodules              <- Lightning datamodules
â”‚   â”œâ”€â”€ models                   <- Lightning models
â”‚   â”œâ”€â”€ utils                    <- Utility scripts
â”‚   â”‚
â”‚   â”œâ”€â”€ eval.py                  <- Run evaluation
â”‚   â””â”€â”€ train.py                 <- Run training
â”‚
â”œâ”€â”€ tests                  <- Tests of any kind
â”‚
â”œâ”€â”€ .env.example              <- Example of file for storing private environment variables
â”œâ”€â”€ .gitignore                <- List of files ignored by git
â”œâ”€â”€ .pre-commit-config.yaml   <- Configuration of pre-commit hooks for code formatting
â”œâ”€â”€ Makefile                  <- Makefile with commands like `make train` or `make test`
â”œâ”€â”€ pyproject.toml            <- Configuration options for testing and linting
â”œâ”€â”€ requirements.txt          <- File for installing python dependencies
â”œâ”€â”€ setup.py                  <- File for installing project as a package
â””â”€â”€ README.md
```

<br>

